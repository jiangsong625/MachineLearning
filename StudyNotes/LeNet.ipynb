{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "导入包  \n",
    "TensorFlow Datasets 是 TensorFlow 生态系统中的一个核心组件，它旨在简化数据获取和预处理流程，为机器学习和深度学习项目提供即用型数据集。TFDS 提供了一系列高质量、标准化的数据集，支持多种数据类型，包括图像、文本、视频等，下面是其主要特点和使用方法的概览："
   ],
   "id": "c6d843d47d42bceb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:27:28.315658Z",
     "start_time": "2024-06-09T11:26:54.288219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras.callbacks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers"
   ],
   "id": "9f226fd0a2b984de",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:33:55.479175Z",
     "start_time": "2024-06-09T11:33:55.471163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 20  # 训练轮数\n",
    "BATCH_SIZE = 128  # 批处理大小\n",
    "VERBOSE = 1  # 是否打印日志\n",
    "OPTIMIZER = optimizers.Adam()  # 优化器\n",
    "VALIDATION_SPLIT = 0.95  # 是指训练集的划分比例，0.95表示训练集95%，验证集5%"
   ],
   "id": "2314cbca2c7fbefc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:28:39.927777Z",
     "start_time": "2024-06-09T11:28:39.909818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_ROWS, IMG_COLS = 28, 28  # 输入图片的维度\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
    "NB_CLASSES = 10  # 输出的类别数"
   ],
   "id": "c5c0e4d0fa0cf6d4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "定义LeNET网络",
   "id": "f844ad0c029e8639"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:28:42.047409Z",
     "start_time": "2024-06-09T11:28:42.034445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model(input_shape, classes):\n",
    "    model = models.Sequential()\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(layers.Convolution2D(20 ,(5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # Flatten => RELU layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(500, activation='relu'))\n",
    "    # a softmax classifier\n",
    "    model.add(layers.Dense(classes, activation='softmax'))\n",
    "    return model"
   ],
   "id": "b8d16924f0e8b65c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `build_model` 函数解析\n",
    "\n",
    "该函数运用 Keras（TensorFlow 库的构成部分）构建了一个序列化的卷积神经网络（CNN）模型，广泛应用于图像分类任务。下文详述模型结构：\n",
    "\n",
    "- **输入层**  \n",
    "  通过`input_shape`参数隐式设定，确保与输入图像尺寸（不含颜色通道）相符。\n",
    "\n",
    "- **卷积层 1**  \n",
    "  添加了20个5x5大小的滤波器，每个滤波器后接ReLU激活函数，负责提取图像基础特征。\n",
    "\n",
    "- **最大池化 1**  \n",
    "  采用2x2大小的最大池化减少空间复杂度，增进特征的平移不变性。\n",
    "\n",
    "- **卷积层 2**  \n",
    "  增加至50个5x5滤波器，深化特征学习，提取更高级特征。\n",
    "\n",
    "- **最大池化 2**  \n",
    "  继续通过2x2最大池化降低维度，简化数据结构。\n",
    "\n",
    "- **展平层**  \n",
    "  将卷积层输出的二维特征图转化为一维向量，适配全连接层。\n",
    "\n",
    "- **全连接层（Dense 1）**  \n",
    "  含500个神经元，使用ReLU激活，整合并强化特征。\n",
    "\n",
    "- **输出层（Dense 2）**  \n",
    "  神经元数等于分类数，采用softmax激活，输出各类别概率，实现多分类。\n",
    "\n",
    "- **模型概览**  \n",
    "  显示模型结构摘要，包括参数总量，帮助评估模型复杂度。\n",
    "\n",
    "- **返回模型**  \n",
    "  构建完毕的模型待编译与训练。\n",
    "\n",
    "此架构作为图像分类的基本CNN模型，为众多项目奠定基础。然而，现代实践倾向于加入批量归一化、dropout机制或Inception模块等，以提升性能和模型的泛化能力。\n"
   ],
   "id": "1325f5e36cf336f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "加载数据集",
   "id": "57005e7cb83b0bec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:28:48.549930Z",
     "start_time": "2024-06-09T11:28:47.884832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "# 重塑\n",
    "X_train = x_train.reshape(x_train.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "X_test = x_test.reshape(x_test.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "# 归一化\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "# \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 转换为one-hot编码\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)"
   ],
   "id": "f9c0f767715ecb75",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9252d2d3e187d669"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:57:17.658272Z",
     "start_time": "2024-06-09T11:57:17.588461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = build_model(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "id": "ff9a213300d668fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 20)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 50)          25050     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               400500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,080\n",
      "Trainable params: 431,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "首先调用了之前定义的`build_model`函数，传入预定义的输入尺寸`INPUT_SHAPE`和类别数`NB_CLASSES`来实例化模型。接着，使用`.compile`方法配置模型的训练设置，其中：\n",
    "- **损失函数**设为`categorical_crossentropy`，这是多分类问题中常用的损失函数。\n",
    "- **优化器**通过变量`OPTIMIZER`指定，具体优化算法（如Adam、RMSprop等）需在调用此代码前定义。\n",
    "- **评估指标**选择了`accuracy`（准确率），用以监测模型在训练和验证过程中的分类准确性。"
   ],
   "id": "a150af7fe772408e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Keras Callbacks 简介\n",
    "\n",
    "Keras `callbacks` 是一组可自定义的函数，它们在训练过程的关键时刻被调用，提供了额外的功能和灵活性。这些功能包括但不限于模型检查点保存、学习率调整、早停策略、日志记录等。以下是几个典型回调的简介：\n",
    "\n",
    "1. **ModelCheckpoint**  \n",
    "   - **功能**：在每个epoch结束时保存模型（可以选择性地仅保存最佳模型）。\n",
    "   - **用途**：保留训练过程中的最佳模型或定期备份模型以防训练中断。\n",
    "\n",
    "2. **EarlyStopping**  \n",
    "   - **功能**：当监控的指标（如验证损失或精度）在一段时间内不再改善时，提前终止训练。\n",
    "   - **用途**：防止过拟合，节省计算资源。\n",
    "\n",
    "3. **LearningRateScheduler**  \n",
    "   - **功能**：根据预设的计划动态调整学习率。\n",
    "   - **用途**：优化学习过程，初始阶段快速下降，后期缓慢调整以精细调整模型。\n",
    "\n",
    "4. **TensorBoard**  \n",
    "   - **功能**：可视化训练过程，包括损失、精度、权重分布等。\n",
    "   - **用途**：帮助理解模型训练动态，调试模型和超参数调优。\n",
    "\n",
    "5. **CSVLogger**  \n",
    "   - **功能**：将训练日志记录到CSV文件中。\n",
    "   - **用途**：便于后续数据分析和模型训练历史跟踪。\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "6098756b322d90bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:20.232055Z",
     "start_time": "2024-06-09T11:32:20.228964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./LeNet_logs')\n",
    "]"
   ],
   "id": "533a0a507b91248e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "eb164722a4d0e930"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:58:22.355657Z",
     "start_time": "2024-06-09T11:57:35.876968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=VERBOSE,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    callbacks=callbacks)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)"
   ],
   "id": "59dae617ca4d1153",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 205ms/step - loss: 1.3201 - accuracy: 0.6310 - val_loss: 0.5170 - val_accuracy: 0.8370\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 189ms/step - loss: 0.3653 - accuracy: 0.8980 - val_loss: 0.2955 - val_accuracy: 0.9127\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 186ms/step - loss: 0.2169 - accuracy: 0.9417 - val_loss: 0.2403 - val_accuracy: 0.9257\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 187ms/step - loss: 0.1504 - accuracy: 0.9593 - val_loss: 0.2324 - val_accuracy: 0.9263\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 187ms/step - loss: 0.1238 - accuracy: 0.9657 - val_loss: 0.1543 - val_accuracy: 0.9528\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 187ms/step - loss: 0.0932 - accuracy: 0.9780 - val_loss: 0.1421 - val_accuracy: 0.9555\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.0701 - accuracy: 0.9833 - val_loss: 0.1264 - val_accuracy: 0.9609\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 188ms/step - loss: 0.0492 - accuracy: 0.9887 - val_loss: 0.1324 - val_accuracy: 0.9591\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 186ms/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 0.1318 - val_accuracy: 0.9580\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 188ms/step - loss: 0.0409 - accuracy: 0.9897 - val_loss: 0.1263 - val_accuracy: 0.9615\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9639\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对于前14次迭代，训练集准确率在0.99左右，验证集准确率在0.98左右。第15次迭代，训练集准确率有所下降。",
   "id": "90fcbfda95c4471d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2ed4ee4517c92900"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:56:57.465898Z",
     "start_time": "2024-06-09T11:56:57.455925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "id": "13e5f3a3d7133745",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09333154559135437\n",
      "Test accuracy: 0.9751999974250793\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "和之前的模型相比，LeNet模型在测试集上的准确率有所提升，从0.91提升到0.99。",
   "id": "616931909a9b1396"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
